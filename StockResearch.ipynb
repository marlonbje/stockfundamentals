{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nimport plotly.io as pio\nimport plotly.graph_objs as go\nfrom plotly.colors import qualitative as pc\nimport yfinance as yf\nimport logging\nimport os\nimport json\nimport time\npio.renderers.default = 'notebook'\n\nclass StockResearch:\n    def __init__(self,file=None,configs=None):\n        self.logger = logging.getLogger(__name__)\n        self.file = file\n        self.configs = configs\n        self.stocks_existing, configs_existing = self._load_stocks(), self._load_configs()\n        if self.stocks_existing:\n            if not configs_existing:\n                self.interval = '1wk'\n                self.freq = 'quarterly'\n            self._get_data()\n        \n    def _load_stocks(self):\n        if self.file is None:\n            return False\n        try:\n            with open(self.file,'r') as f:\n                self.tickers = [i.strip() for i in f.readlines()]\n                if self.tickers:\n                    return True\n                else:\n                    return False\n        except FileNotFoundError:\n            self.logger.error(f'{self.file} not found in cache')\n            return False\n        \n    def _load_configs(self):\n        if self.configs is None:\n            return False\n        try:\n            with open(self.configs,'r') as f:\n                content = json.load(f)\n                try:\n                    self.interval = content['interval']\n                    self.freq = content['freq']\n                    return True\n                except KeyError:\n                    self.logger.error('Configs is missing required data')\n                    return False\n        except FileNotFoundError:\n            self.logger.warning('Configs file not found in cache')\n            return False\n        \n    def _get_data(self):\n        for ticker in self.tickers:\n            if not os.path.exists(f'{ticker}_fundamental_data_{self.freq}.csv'):\n                self._get_fundamentals(ticker)\n                time.sleep(0.5)\n            if not os.path.exists(f'{ticker}_price_data_{self.interval}.csv'):\n                self._get_ohlc(ticker)\n                time.sleep(0.5)\n                \n    def _get_fundamentals(self,ticker):\n        try:\n            obj = yf.Ticker(ticker=ticker)\n            balance = obj.get_balancesheet(freq=self.freq)\n            income = obj.get_income_stmt(freq=self.freq)\n            cashflow = obj.get_cashflow(freq=self.freq)\n            df = pd.concat([income,cashflow],join='inner',axis=0)\n            df = df[df.columns[::-1]]\n            if self.freq == 'quarterly':\n                df.columns = df.columns.to_period('Q').astype('str')\n            else:\n                df.columns = df.columns.year.astype('str')\n            df.to_csv(f'{ticker}_fundamental_data_{self.freq}.csv')\n        except Exception as e:\n            self.logger.warning(f'Could not fetch Income-Statement for {ticker}: {e}')\n    \n    def _get_ohlc(self,ticker):\n        try:\n            df = yf.download(ticker,interval=self.interval,period='max',auto_adjust=True,progress=False)\n            df.columns = ['Open','High','Low','Close','Volume']\n            df.to_csv(f'{ticker}_price_data_{self.interval}.csv')\n        except Exception as e:\n            self.logger.warning(f'Could not fetch OHLC for {ticker}: {e}')\n            \n    def price_to_earnings(self):\n        if self.stocks_existing:\n            pe_df = pd.DataFrame()\n            for ticker in self.tickers:\n                try:\n                    df = pd.read_csv(f'{ticker}_fundamental_data_{self.freq}.csv',index_col=0)\n                    if self.freq == 'yearly':\n                        diluted_eps = df.loc['DilutedEPS'].dropna().iloc[-1]\n                    else:\n                        if len(df.loc['DilutedEPS'].dropna()) < 4:\n                            fill = (4-len(df.loc['DilutedEPS'].dropna()))* df.loc['DilutedEPS'].dropna().mean()\n                            diluted_eps = df.loc['DilutedEPS'].dropna().sum() + fill\n                        else:\n                            diluted_eps = df.loc['DilutedEPS'].dropna().iloc[-4:].sum()\n                        \n                    df = pd.read_csv(f'{ticker}_price_data_{self.interval}.csv',index_col=0)\n                    price = df['Close'].iloc[-1]\n                    pe = price/diluted_eps\n                    if pe < 0:\n                        pe = np.NaN\n                    pe_df.loc[ticker,'PE_ttm'] = round(pe,2)\n                    \n                except Exception as e:\n                    pe = np.NaN\n                    pe_df.loc[ticker,'PE_ttm'] = pe\n                    self.logger.warning(f'Diluted EPS of {ticker} not available')\n                    \n                try:\n                    time.sleep(0.5)\n                    obj = yf.Ticker(ticker=ticker)\n                    fpe = obj.info['forwardPE']\n                    \n                    pe_df.loc[ticker,'Forward_PE'] = round(fpe,2)\n                \n                except Exception as e:\n                    fpe = np.NaN\n                    pe_df.loc[ticker,'Forward_PE'] = fpe\n                    self.logger.warning(f'No forward EPS for {ticker} available')\n                \n                discount = (pe/fpe-1)*100 if (pe and fpe and fpe != 0) else np.NaN\n                pe_df.loc[ticker,'Difference(%)'] = round(discount,2)\n                    \n                    \n            if not pe_df.empty:\n                pe_df.sort_values(by='Difference(%)',ascending=False,inplace=True)\n                return list(pe_df.dropna().index[:int(len(pe_df)*0.33)])\n            else:\n                return []\n        \n    def return_correlation(self,stocks=None):\n        if self.stocks_existing:\n            if stocks is not None and stocks:\n                tickers = stocks\n            else:\n                tickers = self.tickers\n                \n            to_merge = []\n            for ticker in tickers:\n                try:\n                    df = pd.read_csv(f'{ticker}_price_data_{self.interval}.csv',index_col=0,parse_dates=True)\n                    to_merge.append(df['Close'].rename(ticker))\n                except FileNotFoundError:\n                    continue\n            \n            merged_df = pd.concat(to_merge,join='inner',axis=1)\n            corr = merged_df.pct_change(axis=0).corr()\n            \n            fig = go.Figure()\n            fig.add_trace(\n                go.Heatmap(\n                    z=corr,\n                    x=corr.columns,\n                    y=corr.columns,\n                    colorscale='Viridis'\n                )\n            )\n            fig.update_layout(\n                font=dict(size=12,color='#fff'),\n                paper_bgcolor='#000',\n                plot_bgcolor='#000',\n                title=dict(text='Correlation Heatmap',font=dict(size=16,weight='bold')\n                )\n            )\n            fig.show()\n        return True\n    \n    def growth(self,stocks=None):\n        if self.stocks_existing:\n            if stocks is not None and stocks:\n                tickers = stocks\n            else:\n                tickers = self.tickers\n                \n            for ticker in tickers:\n                try:\n                    df = pd.read_csv(f'{ticker}_fundamental_data_{self.freq}.csv',index_col=0)\n                except FileNotFoundError:\n                    continue\n                \n                try:\n                    required = df.loc[['NetIncome','FreeCashFlow','TotalRevenue']].dropna(axis=1)\n                    netmargin = required.loc['NetIncome']/required.loc['TotalRevenue']*100\n                    fcfmargin = required.loc['FreeCashFlow']/required.loc['TotalRevenue']*100\n                    revgrowth = required.loc['TotalRevenue'].pct_change().fillna(0.0) *100\n                    margins = {'FCF-Margin':fcfmargin,'Net-Margin':netmargin}\n                except KeyError:\n                    self.logger.warning(f'{ticker} has not sufficient data')\n                    continue\n                \n                fig = go.Figure()\n                for j,i in enumerate(margins):\n                    fig.add_trace(\n                        go.Bar(\n                            x=margins[i].index,\n                            y=margins[i],\n                            name=i,\n                            marker=dict(color=pc.Plotly[j],line=dict(color='#fff',width=2)),\n                            hovertemplate='<b>%{x}</b><br>%{y:.0f}%'\n                        )\n                    )\n                \n                fig.add_trace(\n                    go.Scatter(\n                        x=revgrowth.index,\n                        y=revgrowth,\n                        name='Revenue-Growth',\n                        mode='lines+markers',\n                        line=dict(color=pc.Plotly[len(margins)],shape='spline',width=3),\n                        marker=dict(color=pc.Plotly[len(margins)],symbol='diamond',size=11,line=dict(color='#fff',width=2)),\n                        hovertemplate='<b>%{x}</b><br>%{y:.0f}%'\n                    )\n                )\n                fig.update_layout(\n                font=dict(size=12,color='#fff'),\n                paper_bgcolor='#000',\n                plot_bgcolor='#000',\n                xaxis=dict(gridcolor='#000'),\n                yaxis=dict(gridcolor='#444',title='(%)'),\n                title=dict(text=f'{ticker} Profitability & Momentum',font=dict(size=16,weight='bold'))\n                )\n                fig.show()\n    \n    def risk_and_return(self,startdate=None,stocks=None):\n        if self.stocks_existing:\n            if stocks is not None and stocks:\n                tickers = stocks\n            else:\n                tickers = self.tickers\n            if startdate is None:\n                self.logger.warning('Stats are calculated with different startpoints for each stock')\n            else:\n                try:\n                    startdate = pd.to_datetime(startdate)\n                except Exception as e:\n                    self.logger.error('Invalid Startdate')\n                    return\n            \n            to_merge = []\n            stats = pd.DataFrame()\n            for ticker in tickers:\n                try:\n                    df = pd.read_csv(f'{ticker}_price_data_{self.interval}.csv',index_col=0,parse_dates=True)['Close']\n                    if startdate is not None:\n                        df = df.loc[df.index>=startdate]\n                        \n                except FileNotFoundError:\n                    continue\n                \n                to_merge.append(df.rename(ticker))\n                if self.interval == '1d':\n                    annualize = 252\n                elif self.interval == '1wk':\n                    annualize = 52\n                elif self.interval == '1mo':\n                    annualize = 12\n                else:\n                    annualize = None\n                    \n                returns = df.pct_change().dropna()*100\n                if annualize is not None:\n                    fixed_rfr = 4\n                    mean = returns.mean()*annualize\n                    std = returns.std()*np.sqrt(annualize)\n                    sr = (mean-fixed_rfr)/std\n                    \n                    stats.loc[ticker,'Average_Return'] = round(mean,2)\n                    stats.loc[ticker,'Return_Volatility'] = round(std,2)\n                    stats.loc[ticker,'Sharpe_Ratio'] = round(sr,2)\n                    \n            if annualize is not None:\n                allstocks_df = pd.concat(to_merge,join='inner',axis=1)\n                allstocksreturn = (allstocks_df.pct_change()*100).dropna().mean(axis=1)\n                allstocks_mean = allstocksreturn.mean() * annualize\n                allstocks_std = allstocksreturn.std() * np.sqrt(annualize)\n                allstocks_sr = (allstocks_mean-fixed_rfr)/allstocks_std\n\n                stats.loc['— Mean —','Average_Return'] = round(allstocks_mean,2)\n                stats.loc['— Mean —','Return_Volatility'] = round(allstocks_std,2)\n                stats.loc['— Mean —','Sharpe_Ratio'] = round(allstocks_sr,2)\n            \n            if not stats.empty:\n                print(stats.sort_values(by='Sharpe_Ratio',ascending=False))\n                \n            fig = go.Figure()\n            fig.add_trace(\n                go.Scatter(\n                    x=allstocks_df.index[1:],\n                    y=(allstocks_df.mean(axis=1).iloc[1:]/allstocks_df.iloc[0].mean()-1)*100,\n                    mode='lines',\n                    line=dict(color=pc.Plotly[0],width=1),\n                    fill='tozeroy',\n                    name='Return',\n                    hovertemplate='<b>%{x}</b><br>%{y:.0f}%'\n                )\n            )\n            fig.update_layout(\n                paper_bgcolor='#000',\n                plot_bgcolor='#000',\n                xaxis_gridcolor='#000',\n                yaxis=dict(gridcolor='#444',title='Return(%)'),\n                font=dict(color='#fff',size=12),\n                title=dict(text='Historic eqw-Return',font=dict(size=16,weight='bold'))\n            )\n            fig.show()\n            \n            if annualize is None:\n                self.logger.warning('Stats only available for [1d,1wk,1mo]')\n            return True\n                                 \n    \n    def __call__(self):\n        dc = self.price_to_earnings()\n        self.growth(dc)\n        self.return_correlation(dc)\n        self.risk_and_return('2023-01-01',dc)\n                \n            \nif __name__ == '__main__':\n    logging.basicConfig(level=logging.WARNING)\n    obj = StockResearch('DJI.txt','configs2.json')\n    obj()",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}